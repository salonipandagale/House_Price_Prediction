# -*- coding: utf-8 -*-
"""Data_analysis_(House Price Prediction).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qnWWxEWRV20KFKJWgznblCZiTXStFnie
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

#diplay all the columns of dataframe
pd.pandas.set_option("display.max_columns", None)

#loading the dataset
dataset = pd.read_csv("/content/AmesHousing_actual.csv")
dataset.info()

dataset.shape

dataset.head()

dataset.columns

#count null values in each columns
#this code tells if column names are null ? --> will always answer false, correct code is below
columns = np.array(dataset.columns.isnull())
columns

#count null values in each columns
null_count = np.array(dataset.isnull().sum())
for i in null_count :
     if i>0 :
      print(i)

null_count = dataset.isnull().sum()[dataset.isnull().sum()>0]
null_count

#here we caalculate the percentage of NaN value in each feature
#1 - make list of features having missing values

feature_with_na =[ features for features in dataset.columns if dataset[features].isnull().sum()>0]

#print features name along with percentage of missing values
for feature in feature_with_na :
  print(feature, " -- > " , np.round(dataset[feature].isnull().mean(), 4), "%missing value" )

"""Since there are many missing values we need to plot some graphs to check relationship between missing values and final sales price __ we will see if missing values are impacting outcome ?

"""

for feature in feature_with_na :
  data = dataset.copy()
  #for feature with null values will be 1, and not null will be 0
  data[feature]= np.where(data[feature].isnull(), 1,0)

  #lets calculate the mean saleprice where the information is missing or present
  data.groupby(feature)['SalePrice'].median().plot.bar()
  plt.title(feature)
  plt.show()

"""So from the above graphs we clearly see the NaN values are impacting the outcomes(prices are either incrasing or decreasing due to  missing values ) , so we will replace nan with something meaning full in feature engineering section"""

#lets check numerical features list

numerical_feature = [feature for feature in dataset.columns if dataset[feature].dtype != 'O']
print('Number of numerical variables: ', len(numerical_feature))

#lets visualise dataset only with numerical variables
dataset[numerical_feature].head()

"""**Temporal_variable**
from the dataset we see we have year variable,We have extract information from the datetime variables like no of years or no of days. One example in this specific scenario can be difference in years between the year the house was built and the year the house was sold. We will be performing this analysis in the Feature Engineering
"""

#list of variables that contains year information

year_feature = [feature for feature in numerical_feature if 'Yr' in feature or 'Year' in feature]
year_feature

# let's explore the content of these year variables
for feature in year_feature:
    print(feature, dataset[feature].unique())

#lets analyse the temporal datetime variable
#we will check if htere is relation between year of house sold and saleprice'

dataset.groupby('Yr Sold')['SalePrice'].median().plot()
plt.xlabel('Year Sold')
plt.ylabel('Median House Price')
plt.title("House Price vs YearSold")

year_feature

#now we will compare the difference between all years feature with SalesPrice
for feature in year_feature :
  if feature != 'Yr Sold' :
    data = dataset.copy()
    data[feature] = data['Yr Sold']- data[feature]
    plt.scatter(data[feature], data['SalePrice'])
    plt.xlabel(feature)
    plt.ylabel('SalePrice')
    plt.show()

#numerical variable are of two types - Continuous and discrete
discrete_feature = [feature for feature in numerical_feature if (len(dataset[feature].unique())<25) and feature not in year_feature +['PID']]
print("Discrete Variable Count: {}".format(len(discrete_feature)))

for feature in discrete_feature :
  data = dataset.copy()
  data.groupby(feature)["SalePrice"].median().plot.bar()
  plt.xlabel(feature)
  plt.ylabel("SalePrice")
  plt.show()

continuous_variable = [feature for feature in numerical_feature if feature not in  discrete_feature + year_feature +['PID']]
print("continuous_variables count : {}".format(len(continuous_variable)))

#lets plot continuous features also
for feature in continuous_variable :
  data= dataset.copy()
  data[feature].hist(bins=25)
  plt.xlabel(feature)
  plt.ylabel("Count")
  plt.title(feature)
  plt.show()

for feature in continuous_variable :
  data = dataset.copy()
  if 0 in data[feature].unique() :
    pass
  else :
    data[feature] = np.log(data[feature])
    data["SalePrice"]= np.log(data["SalePrice"])
    plt.scatter(data[feature], data["SalePrice"])
    plt.xlabel(feature)
    plt.ylabel("SalePrice")
    plt.show()

"""**Let's Handle Outliers**"""

for feature in continuous_variable :
  data = dataset.copy()
  if 0 in data[feature].unique():
    pass
  else :
    data[feature] = np.log(data[feature])
    data.boxplot(column = feature)
    plt.ylabel(feature)
    plt.title(feature)
    plt.show()

"""**Categorical Variable**"""

categorical_variable = [feature for feature in dataset.columns if data[feature].dtype == 'O']
categorical_variable

dataset[categorical_variable].head()

#lets check how many uniques values are there in each column :
for feature in categorical_variable :
  print("The feature is ->   {} \n and number of the unique values are : {}  \n".format(feature, len(data[feature].unique())))

#lets plot all plots for categorical features

for feature in categorical_variable:
  data = dataset.copy()
  data.groupby(feature)["SalePrice"].median().plot.bar()
  plt.xlabel(feature)
  plt.ylabel("Sale Price")
  plt.title(feature)
  plt.show()